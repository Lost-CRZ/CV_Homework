{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Dv8absVKufcA",
   "metadata": {
    "id": "Dv8absVKufcA"
   },
   "source": [
    "# Semantic Segmentation with Deep Learning: Training and Testing on Colab\n",
    "\n",
    "Insert the following Javascript snippet into your browser console so that your Colab runtime won't time out. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n",
    "```Javascript\n",
    "function ClickConnect(){\n",
    "    console.log(\"Clicked on connect button\"); \n",
    "    document.querySelector(\"colab-connect-button\").click()\n",
    "}\n",
    "setInterval(ClickConnect,60000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdweXW5Xqd6R",
   "metadata": {
    "id": "bdweXW5Xqd6R"
   },
   "source": [
    "Zip up your code locally with `python zip_for_colab.py`, and upload your `cv_proj5.zip` file. Hit refresh, then run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ah8PNwYTqM1G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah8PNwYTqM1G",
    "outputId": "9c29b07d-0639-462a-a280-87196052283e"
   },
   "outputs": [],
   "source": [
    "!unzip cv_proj5_colab.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0pf627lnqsTo",
   "metadata": {
    "id": "0pf627lnqsTo"
   },
   "source": [
    "Install the `proj5_code` module locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sEkEfbqNqxa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEkEfbqNqxa4",
    "outputId": "0fa88998-700a-433b-8a11-9a3ee2aa5f77"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-franchise",
   "metadata": {
    "id": "sensitive-franchise"
   },
   "source": [
    "Download ImageNet-pretrained ResNet-50:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-explosion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bound-explosion",
    "outputId": "44715d2e-2c34-4731-ab3a-4623dbf31a30"
   },
   "outputs": [],
   "source": [
    "!wget -O \"resnet50_v2.pth\" --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w5pRmLJXvmQQA5PtCbHhZc_uC4o0YbmA'\n",
    "!mkdir initmodel && mv resnet50_v2.pth initmodel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yZDeFtlyuXNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZDeFtlyuXNz",
    "outputId": "95b172dd-8447-43eb-c45a-b7ec3c80ea35"
   },
   "outputs": [],
   "source": [
    "# The ImageNet-pretrained ResNet-50 weights should be 99 MB\n",
    "!ls -ltrh initmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7wzfFzyHupog",
   "metadata": {
    "id": "7wzfFzyHupog"
   },
   "source": [
    "Download the Camvid dataset images. It's 700 MB, but it should only take 30 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-delaware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intellectual-delaware",
    "outputId": "da7a478b-0887-4f7c-dbce-f823eac18653"
   },
   "outputs": [],
   "source": [
    "!chmod +rwx download_dataset.sh\n",
    "!sed -i -e 's/\\r$//' download_dataset.sh\n",
    "!./download_dataset.sh Camvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PGBUoTc9Aj0t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGBUoTc9Aj0t",
    "outputId": "c88cd1e5-7939-49ad-a89c-d41feaa9ef73"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "!cd Camvid && unzip camvid_semseg11.zip && cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AC_-gfRptGgF",
   "metadata": {
    "id": "AC_-gfRptGgF"
   },
   "source": [
    "We'll now set some default hyperparameters for training. Choose the number of epochs you'd like to train for (for PSPNet, it will take ~30 min for 50 epochs, or ~70 min for 100 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-major",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "absent-major",
    "outputId": "5c0fd99f-f7ee-48f1-f445-59da6d42d2c8"
   },
   "outputs": [],
   "source": [
    "!python --version\n",
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    **{\n",
    "        # DATA\n",
    "        \"names_path\": \"./dataset_lists/camvid-11/camvid-11_names.txt\",\n",
    "        \"data_root\": \"./Camvid/\",\n",
    "        \"train_list\": \"./src/dataset_lists/camvid-11/list/train.txt\",  \n",
    "        \"val_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"classes\": 11,\n",
    "        # TRAIN\n",
    "        \"arch\": \"PSPNet\", #  \"SimpleSegmentationNet\", # \n",
    "        \"save_path\": \"\",\n",
    "        \"epochs\": 5,\n",
    "        \"zoom_factor\": 8,\n",
    "        \"use_ppm\": True,\n",
    "        \"aux_weight\": 0.4,\n",
    "        \"aux_loss\": True,\n",
    "        \"layers\": 50,\n",
    "        \"workers\": 2,\n",
    "        \"batch_size\": 32,\n",
    "        \"batch_size_val\": 32,\n",
    "        \"data_aug\": True,\n",
    "        \"short_size\": 240,\n",
    "        \"train_h\": 201,\n",
    "        \"train_w\": 201,\n",
    "        \"init_weight\": \"./initmodel/resnet50_v2.pth\",\n",
    "        \"scale_min\": 0.5,  # minimum random scale\n",
    "        \"scale_max\": 2.0,  # maximum random scale\n",
    "        \"rotate_min\": -10,  # minimum random rotate\n",
    "        \"rotate_max\": 10,  # maximum random rotate\n",
    "        \"ignore_label\": 255,\n",
    "        \"base_lr\": 0.01,\n",
    "        \"start_epoch\": 0,\n",
    "        \"power\": 0.9,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"manual_seed\": 0,\n",
    "        \"print_freq\": 10,\n",
    "        \"save_freq\": 1,\n",
    "        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n",
    "        \"multiprocessing_distributed\": False,\n",
    "        # INFERENCE\n",
    "        \"dataset\": \"camvid-11\",\n",
    "        \"base_size\": 240,\n",
    "        \"test_h\": 201,\n",
    "        \"test_w\": 201,\n",
    "        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        \"test_list\": \"./src/dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"vis_freq\": 10,\n",
    "        \"pretrained\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "args.save_path = f\"exp/camvid/{args.arch}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-blade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "increased-blade",
    "outputId": "a6023f1e-e981-4496-c2d9-2299ef7610b1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "from vision.trainer import main_worker\n",
    "print(args)\n",
    "main_worker(args, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7or_wjTqvX6H",
   "metadata": {
    "id": "7or_wjTqvX6H"
   },
   "source": [
    "We'll now create full-resolution predictions for the full val set, and compute mIoU against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-vegetation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "worst-vegetation",
    "outputId": "12e70bf3-c7d7-4181-a781-f617ff7999cb"
   },
   "outputs": [],
   "source": [
    "from vision.test import test_model\n",
    "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ETWCIkf1vfCP",
   "metadata": {
    "id": "ETWCIkf1vfCP"
   },
   "source": [
    "**Important**: Record the mIoU listed in the output above, and the IoU per each class. You can find the results later in `train_epoch_{args.epochs}/camvid-11/720/results.txt`.\n",
    "\n",
    "Now, let's take a look at what our results look like. We'll make a 2x3 image grid with the following structure:\n",
    "\n",
    "|RGB Image | Blended RGB and Ground Truth | Ground Truth \n",
    "|:-: | :-: | :-:\n",
    "| RGB Image | Blended RGB and Prediction | Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cDpIrDQvvBq5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "cDpIrDQvvBq5",
    "outputId": "bc1be37a-86ea-447c-ef36-1adf53e6033a"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rgb_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/rgb_mask_predictions\"\n",
    "\n",
    "def show_image_grid(rgb_predictions_dir: str, img_fname: str) -> None:\n",
    "  img_grid = imageio.imread(f'{rgb_predictions_dir}/{img_fname}')\n",
    "  plt.figure(figsize=(15,7))\n",
    "  plt.imshow(img_grid)\n",
    "  plt.show()\n",
    "\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_07977.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JOxOOpJ-wDHa",
   "metadata": {
    "id": "JOxOOpJ-wDHa"
   },
   "source": [
    "We'll look at more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wJo0THuZvDkU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wJo0THuZvDkU",
    "outputId": "3af4b638-fed6-4f66-c29b-d65a75524e25"
   },
   "outputs": [],
   "source": [
    "show_image_grid(rgb_predictions_dir, \"0016E5_07997.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08017.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08037.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08057.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08077.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08097.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08117.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08137.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08157.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VFCSB5B23t19",
   "metadata": {
    "id": "VFCSB5B23t19"
   },
   "source": [
    "Now, zip up your predictions on the test set for your best model, **download them locally to your machine**, and submit these to Gradescope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VbYbqcNn3eS2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbYbqcNn3eS2",
    "outputId": "5596b314-cbd0-43d0-c5cf-d767d6a66bd7"
   },
   "outputs": [],
   "source": [
    "grayscale_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/gray\"\n",
    "!ls -ltrh $grayscale_predictions_dir\n",
    "!zip -r grayscale_predictions.zip $grayscale_predictions_dir\n",
    "!ls -ltrh grayscale_predictions.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DBuC3SzAlQcU",
   "metadata": {
    "id": "DBuC3SzAlQcU"
   },
   "source": [
    "\n",
    "**Transfer Learning:** \n",
    "Zip the Kitti dataset and upload it to colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IJ6oQCX--9Xd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJ6oQCX--9Xd",
    "outputId": "2c846383-86f0-410e-8a6f-e1ba22c21da0"
   },
   "outputs": [],
   "source": [
    "!unzip kitti.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ib-UgbbzCXVI",
   "metadata": {
    "id": "ib-UgbbzCXVI"
   },
   "source": [
    "Load the model trained on the Camvid dataset. Change to your best model if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3UJ1porI_f0J",
   "metadata": {
    "id": "3UJ1porI_f0J"
   },
   "outputs": [],
   "source": [
    "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
    "# args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_200.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2FXFsF3Msg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a2FXFsF3Msg",
    "outputId": "2a0accd9-b8ef-4ccc-b2a7-bd8cee42845d"
   },
   "outputs": [],
   "source": [
    "args.data_root = \"./kitti\"\n",
    "args.classes = 2\n",
    "args.save_path = f\"exp/kitti/{args.arch}/model\"\n",
    "args.batch_size = 32\n",
    "args.batch_size_val = 1\n",
    "args.dataset = \"kitti\"\n",
    "args.evaluate = False\n",
    "args.epochs = 10\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CdrbddFtHSw6",
   "metadata": {
    "id": "CdrbddFtHSw6"
   },
   "outputs": [],
   "source": [
    "args.base_lr = 0.01\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8qtSkys6eyNb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qtSkys6eyNb",
    "outputId": "003e2e84-a538-4539-f4cd-d439dc6f2e9c"
   },
   "outputs": [],
   "source": [
    "from src.vision.trainer import transfer_train\n",
    "transfer_train(args, torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "proj5_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
